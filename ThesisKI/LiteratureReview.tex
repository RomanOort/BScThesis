\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{relsize}
\usepackage{mathtools}
\usepackage{textcomp}
\usepackage{eurosym}
\title{Literature Draft}
\author{Roman Oort}
\date{\today}
\DeclareMathOperator*{\plim}{plim}
\begin{document}

\maketitle

\tableofcontents

\newpage

\section{Literature Review}

\subsection{Social Learning}
Social learning is a field of study used in various different disciplines, ranging from economy to psychology, concerning the process of changing beliefs in groups \cite{reed2010sociallearning}. Research in this field is dedicated to determining how individuals, and groups as a whole, change their beliefs and actions based on beliefs and actions of those around them. Many models have been proposed to formalize this process \cite{golub2017learning}, with the DeGroot model being one of the most prominent \cite{degroot1974concensus}.

\subsection{DeGroot Model}
\subsubsection{Agent Interaction}
A DeGroot model consists of a finite set of $N=\{1, 2, ..., n\}$ of agents all interacting with each other and passing information. The $n \times n$ \emph{interaction} matrix \textbf{T} describes the nature of these interactions: whose opinions are heeded by whom, and how much so, among others. If the entry $\textbf{T}_{ij} > 0$ it indicates that agent $i$ listens to agent $j$, and the value of this entry determines how much weight agent $i$ places on agents $j$'s opinion: the higher this value the more important $j$'s opinion is to $i$. It is important to note that \textbf{T} is a positive matrix, meaning it is not possible for an agent to place a negative weight on another agents opinion, they are only ever capable of ignoring other agents, or agreeing with them in some manner. 

Furthermore, the weight matrix \textbf{T} is a row-stochastic matrix, meaning that its rows sum to one:
\begin{align*}
    \sum_{j=1}^{n} \textbf{T}_{ij} = 1
\end{align*}

Another important property of this interaction matrix \textbf{T} is that it is not necessarily symmetrical, making it entirely possible for an agent $i$ to hold the opinion of agent $j$ in high regard, while $j$ thinks very little of $i$'s opinion, or not even anything  at all.

\newpage

\subsubsection{Belief \& Learning}
As mentioned before, the DeGroot model is a model used to simulate social learning, and is often referred to as a form of \textit{naive social learning}. This means that this model simulates the development the beliefs of the agents present in the network, as time progresses, but the updating rule at each time-step is a very simple rule and is therefore called naive.

The belief of an agent $i \in N$ at a time $t \in \{0, 1, 2, ...\}$ is denoted as $p_{i}^{(t)}$, where this belief is generally taken as a real number on the interval $[0, 1]$. At the start of the process, $t=0$, each agent $i$ is given a personal belief, through a private signal,
\begin{align*}
    p_{i}^{(0)} = \mu + e_i
\end{align*}
where $\mu$ is a real number, again on the interval $[0, 1]$, assumed to be the true state of the network, and $e_i$ is the random, zero mean, noise of agent $i$'s signal. \newline
The beliefs of all agents in the network, are aggregated into the belief vector $\textbf{p}^{(t)}$, where the $i$th entry corresponds to the belief of agent $i$, at time $t$.

As time progresses the agents in the network update their own belief based on the beliefs of the agents around them, using the following updating rule:
\begin{equation}
    \textbf{p}^{(t)} = \textbf{T}\textbf{p}^{(t-1)} \label{updating:standard}
\end{equation}
which means that an agent $i$'s opinion, at time $t$, is simply the matrix multiplication of the interaction matrix and the belief vector at time $t-1$. This makes the update rule for an agent $i$ in the network the follows:
\begin{align*}
    p_{i}^{(t)} = \sum_{j=1}^{n}T_{ij}p_{j}^{(t-1)}
\end{align*}
which simply amounts to the weighted sum of the beliefs of all neighbours of agent $i$ in the network, where agent $i$'s neighbours are those agents $j$ in the network to whom $i$ listens.

Furthermore, it is possible to compute the belief vector $\textbf{p}^{(t)}$, without computing the belief vector at every preceding $t^\prime < t$, the formula for which can be derived from equation \ref{updating:standard}, as follows:
\begin{align*}
    \textbf{p}^{(t)} &= \textbf{T}\textbf{p}^{(t-1)} \\
    &= \textbf{T}(\textbf{T}\textbf{p}^{(t-2)}) \text{, which, eventually, becomes}\\
    &= \textbf{T}^{t}\textbf{p}^{(0)}
\end{align*}

\newpage

\subsubsection{Convergence}
As we are interested in the spread of information through the network, and whether the agents in a network will learn the supposed true state of the world, an important notion is the concept of \emph{convergence}. A matrix \textbvf{T} is said to convergent if
\begin{equation*}
    \lim_{t\to\infty} \textbf{T}^t\textbf{p}
\end{equation*}
exists for all $\textbf{p} \in [0, 1]^n$. That is to say, as time progresses sufficiently, the beliefs of the agents, independent of their starting signal, approach a constant value and no longer change.

Another important property is \emph{aperiodicity}, which concerns the cycles, which are paths through the network that start and end at the same agent. A network is said to be aperiodic if the largest common divisor of the length of all cycles in the network is no more than 1. This condition is automatically satisfied as long as there is at least one agent present in the network who has a link to themselves, as this creates a cycle of length one.

The following statements, provided that \textbf{T} is strongly connected, that is to say, there exists some directed path between any two agents in the network,  are equivalent:
\begin{itemize}
    \item[-] \textbf{T} is convergent
    \item[-] \textbf{T} is aperiodic
    \item[-] There is some unique left eigenvector, \textbf{s}, of \textbf{T}, corresponding to the eigenvalue $\lambda=1$, such that, for every \textbf{p}$\in [0,1]^n$,
    \begin{align*}
        (\lim_{t\to\infty}\textbf{T}^t\textbf{p}) = \textbf{sp}
    \end{align*}
\end{itemize}

\newpage


\bibliographystyle{apalike}
\bibliography{references.bib}
\end{document}



